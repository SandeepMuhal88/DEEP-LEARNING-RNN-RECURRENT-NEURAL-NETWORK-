{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53dc3920",
   "metadata": {},
   "source": [
    "# Task 1 – Basic Word Tokenization + Embedding Layer\n",
    "**  1. Take a short set of sentences (5–6 sentences).\n",
    "\n",
    "    2. Tokenize them using Keras Tokenizer.\n",
    "    \n",
    "    3. Create an Embedding layer (say output_dim=8) and run them through a simple neural network.\n",
    "    \n",
    "    4. Just print the embedding output for each word.\n",
    "    \n",
    "    📌 Goal: Understand how words turn into vectors inside the embedding.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93b35ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,LSTM,Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3f838d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs= [\n",
    "    'Creating an immersive world for a story is like building a house from the ground up, brick by brick.',\n",
    "    'Every detail, from the scent of the air to the texture of the cobblestones underfoot, contributes to its foundation.',\n",
    "    'The goal is to make the setting feel so real that the reader can step inside, becoming a part of the landscape.',\n",
    "    'A well-crafted world isnt just a backdrop its a character in its own right, with a history, a culture, and secrets waiting to be unearthed.',\n",
    "    'When a story world is thoughtfully constructed, it enriches the plot and allows the characters to feel more authentic.',\n",
    "    'Its this deep level of engagement that keeps readers turning pages long into the night.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ac83c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffe9aa68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Creating an immersive world for a story is like building a house from the ground up, brick by brick.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8c6b3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fee196c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'a': 2,\n",
       " 'to': 3,\n",
       " 'of': 4,\n",
       " 'its': 5,\n",
       " 'world': 6,\n",
       " 'is': 7,\n",
       " 'story': 8,\n",
       " 'from': 9,\n",
       " 'brick': 10,\n",
       " 'feel': 11,\n",
       " 'that': 12,\n",
       " 'and': 13,\n",
       " 'creating': 14,\n",
       " 'an': 15,\n",
       " 'immersive': 16,\n",
       " 'for': 17,\n",
       " 'like': 18,\n",
       " 'building': 19,\n",
       " 'house': 20,\n",
       " 'ground': 21,\n",
       " 'up': 22,\n",
       " 'by': 23,\n",
       " 'every': 24,\n",
       " 'detail': 25,\n",
       " 'scent': 26,\n",
       " 'air': 27,\n",
       " 'texture': 28,\n",
       " 'cobblestones': 29,\n",
       " 'underfoot': 30,\n",
       " 'contributes': 31,\n",
       " 'foundation': 32,\n",
       " 'goal': 33,\n",
       " 'make': 34,\n",
       " 'setting': 35,\n",
       " 'so': 36,\n",
       " 'real': 37,\n",
       " 'reader': 38,\n",
       " 'can': 39,\n",
       " 'step': 40,\n",
       " 'inside': 41,\n",
       " 'becoming': 42,\n",
       " 'part': 43,\n",
       " 'landscape': 44,\n",
       " 'well': 45,\n",
       " 'crafted': 46,\n",
       " 'isnt': 47,\n",
       " 'just': 48,\n",
       " 'backdrop': 49,\n",
       " 'character': 50,\n",
       " 'in': 51,\n",
       " 'own': 52,\n",
       " 'right': 53,\n",
       " 'with': 54,\n",
       " 'history': 55,\n",
       " 'culture': 56,\n",
       " 'secrets': 57,\n",
       " 'waiting': 58,\n",
       " 'be': 59,\n",
       " 'unearthed': 60,\n",
       " 'when': 61,\n",
       " 'thoughtfully': 62,\n",
       " 'constructed': 63,\n",
       " 'it': 64,\n",
       " 'enriches': 65,\n",
       " 'plot': 66,\n",
       " 'allows': 67,\n",
       " 'characters': 68,\n",
       " 'more': 69,\n",
       " 'authentic': 70,\n",
       " 'this': 71,\n",
       " 'deep': 72,\n",
       " 'level': 73,\n",
       " 'engagement': 74,\n",
       " 'keeps': 75,\n",
       " 'readers': 76,\n",
       " 'turning': 77,\n",
       " 'pages': 78,\n",
       " 'long': 79,\n",
       " 'into': 80,\n",
       " 'night': 81}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "827818c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be1dbbfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('creating', 1),\n",
       "             ('an', 1),\n",
       "             ('immersive', 1),\n",
       "             ('world', 3),\n",
       "             ('for', 1),\n",
       "             ('a', 9),\n",
       "             ('story', 2),\n",
       "             ('is', 3),\n",
       "             ('like', 1),\n",
       "             ('building', 1),\n",
       "             ('house', 1),\n",
       "             ('from', 2),\n",
       "             ('the', 12),\n",
       "             ('ground', 1),\n",
       "             ('up', 1),\n",
       "             ('brick', 2),\n",
       "             ('by', 1),\n",
       "             ('every', 1),\n",
       "             ('detail', 1),\n",
       "             ('scent', 1),\n",
       "             ('of', 4),\n",
       "             ('air', 1),\n",
       "             ('to', 5),\n",
       "             ('texture', 1),\n",
       "             ('cobblestones', 1),\n",
       "             ('underfoot', 1),\n",
       "             ('contributes', 1),\n",
       "             ('its', 4),\n",
       "             ('foundation', 1),\n",
       "             ('goal', 1),\n",
       "             ('make', 1),\n",
       "             ('setting', 1),\n",
       "             ('feel', 2),\n",
       "             ('so', 1),\n",
       "             ('real', 1),\n",
       "             ('that', 2),\n",
       "             ('reader', 1),\n",
       "             ('can', 1),\n",
       "             ('step', 1),\n",
       "             ('inside', 1),\n",
       "             ('becoming', 1),\n",
       "             ('part', 1),\n",
       "             ('landscape', 1),\n",
       "             ('well', 1),\n",
       "             ('crafted', 1),\n",
       "             ('isnt', 1),\n",
       "             ('just', 1),\n",
       "             ('backdrop', 1),\n",
       "             ('character', 1),\n",
       "             ('in', 1),\n",
       "             ('own', 1),\n",
       "             ('right', 1),\n",
       "             ('with', 1),\n",
       "             ('history', 1),\n",
       "             ('culture', 1),\n",
       "             ('and', 2),\n",
       "             ('secrets', 1),\n",
       "             ('waiting', 1),\n",
       "             ('be', 1),\n",
       "             ('unearthed', 1),\n",
       "             ('when', 1),\n",
       "             ('thoughtfully', 1),\n",
       "             ('constructed', 1),\n",
       "             ('it', 1),\n",
       "             ('enriches', 1),\n",
       "             ('plot', 1),\n",
       "             ('allows', 1),\n",
       "             ('characters', 1),\n",
       "             ('more', 1),\n",
       "             ('authentic', 1),\n",
       "             ('this', 1),\n",
       "             ('deep', 1),\n",
       "             ('level', 1),\n",
       "             ('engagement', 1),\n",
       "             ('keeps', 1),\n",
       "             ('readers', 1),\n",
       "             ('turning', 1),\n",
       "             ('pages', 1),\n",
       "             ('long', 1),\n",
       "             ('into', 1),\n",
       "             ('night', 1)])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b72f620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.document_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ed89d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[14, 15, 16, 6, 17, 2, 8, 7, 18, 19, 2, 20, 9, 1, 21, 22, 10, 23, 10],\n",
       " [24, 25, 9, 1, 26, 4, 1, 27, 3, 1, 28, 4, 1, 29, 30, 31, 3, 5, 32],\n",
       " [1,\n",
       "  33,\n",
       "  7,\n",
       "  3,\n",
       "  34,\n",
       "  1,\n",
       "  35,\n",
       "  11,\n",
       "  36,\n",
       "  37,\n",
       "  12,\n",
       "  1,\n",
       "  38,\n",
       "  39,\n",
       "  40,\n",
       "  41,\n",
       "  42,\n",
       "  2,\n",
       "  43,\n",
       "  4,\n",
       "  1,\n",
       "  44],\n",
       " [2,\n",
       "  45,\n",
       "  46,\n",
       "  6,\n",
       "  47,\n",
       "  48,\n",
       "  2,\n",
       "  49,\n",
       "  5,\n",
       "  2,\n",
       "  50,\n",
       "  51,\n",
       "  5,\n",
       "  52,\n",
       "  53,\n",
       "  54,\n",
       "  2,\n",
       "  55,\n",
       "  2,\n",
       "  56,\n",
       "  13,\n",
       "  57,\n",
       "  58,\n",
       "  3,\n",
       "  59,\n",
       "  60],\n",
       " [61, 2, 8, 6, 7, 62, 63, 64, 65, 1, 66, 13, 67, 1, 68, 3, 11, 69, 70],\n",
       " [5, 71, 72, 73, 4, 74, 12, 75, 76, 77, 78, 79, 80, 1, 81]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence=tokenizer.texts_to_sequences(docs)\n",
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd832876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c93d757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14 15 16  6 17  2  8  7 18 19  2 20  9  1 21 22 10 23 10  0  0  0  0  0\n",
      "   0  0]\n",
      " [24 25  9  1 26  4  1 27  3  1 28  4  1 29 30 31  3  5 32  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 1 33  7  3 34  1 35 11 36 37 12  1 38 39 40 41 42  2 43  4  1 44  0  0\n",
      "   0  0]\n",
      " [ 2 45 46  6 47 48  2 49  5  2 50 51  5 52 53 54  2 55  2 56 13 57 58  3\n",
      "  59 60]\n",
      " [61  2  8  6  7 62 63 64 65  1 66 13 67  1 68  3 11 69 70  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 5 71 72 73  4 74 12 75 76 77 78 79 80  1 81  0  0  0  0  0  0  0  0  0\n",
      "   0  0]]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import pad_sequences\n",
    "\n",
    "pad_sequences=pad_sequences(sequence,padding='post')\n",
    "print(pad_sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60be0314",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Project-to-learn\\.machine\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">139</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,368</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m139\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m10,368\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">142,081</span> (555.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m142,081\u001b[0m (555.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">142,081</span> (555.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m142,081\u001b[0m (555.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(input_dim=81,output_dim=128,input_length=139))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.build(input_shape=(None,139))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".machine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
