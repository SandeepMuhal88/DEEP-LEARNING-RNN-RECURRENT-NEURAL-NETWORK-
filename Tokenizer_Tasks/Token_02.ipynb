{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96479161",
   "metadata": {},
   "source": [
    "### Task 2 â€“ Sentiment Classification with Tokenizer + Embedding\n",
    "Dataset: Use the built-in IMDb dataset from tf.keras.datasets.\n",
    "\n",
    "Tokenize text, pad sequences to the same length.\n",
    "\n",
    "Use an Embedding layer + LSTM to classify positive/negative sentiment.\n",
    "\n",
    "Train for at least 2 epochs and see accuracy changes.\n",
    "\n",
    "ðŸ“Œ Goal: Use tokenization + embeddings in a real classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac8e94ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow \n",
    "from tensorflow import keras\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e666402b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,) (25000,)\n",
      "(25000,) (25000,)\n"
     ]
    }
   ],
   "source": [
    "vacab_size=10000\n",
    "(X_train,y_train) ,(X_test,y_test)=imdb.load_data(num_words=vacab_size)\n",
    "print(X_train.shape,y_train.shape)\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89513157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aafa7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in vocabulary: 88584\n",
      "Actual words used (limited by vocab_size): 10000\n"
     ]
    }
   ],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "print(\"Total words in vocabulary:\", len(word_index))  # Usually around 88,585\n",
    "print(\"Actual words used (limited by vocab_size):\", vacab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2db7dcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences to a fixed length\n",
    "maxlen = 256\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dad3ac9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,   19,  178,   32],\n",
       "       [   0,    0,    0, ...,   16,  145,   95],\n",
       "       [   0,    0,    0, ...,    7,  129,  113],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    4, 3586,    2],\n",
       "       [   0,    0,    0, ...,   12,    9,   23],\n",
       "       [   0,    0,    0, ...,  204,  131,    9]], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".machine (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
